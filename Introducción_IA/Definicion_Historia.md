# Introducción a la Inteligencia Artificial

## Definición de la IA

La inteligencia artificial (IA) es un campo fascinante, pero ¿cómo la definimos exactamente? No hay una única respuesta.

https://www.youtube.com/watch?v=FUd_RQfbQus

Existen diferentes maneras de entender la IA, y generalmente se dividen en cuatro enfoques principales:

1️⃣ _Comportamiento Humano: enfoque de la Prueba de Turing_
     Sistemas que actúan como humanos – Buscan _imitar el comportamiento humano_ en tareas que requieren inteligencia, como el reconocimiento de voz o la conducción autónoma. 

    _La Prueba de Turing, propuesta por Alan Turing 1950. 
    Ver el siguiente video https://www.youtube.com/watch?v=3wLqsRLvV-c

    Ejemplo: Chatbots avanzados o robots humanoides.

2️⃣ _Pensar como un humano: el enfoque del modelo cognitivo_ 
    Sistemas que piensan como humanos – Intentan replicar _procesos mentales humanos_, como la toma de decisiones y el aprendizaje. 

    Ejemplo: Modelos que simulan cómo funciona el cerebro.

3️⃣ _Pensamiento racional: el enfoque de las leyes del pensamiento_
    Sistemas que piensan racionalmente – Se centran en los cálculos y razonamientos lógicos que permiten percibir el entorno y tomar decisiones. 
    El filósofo griego Aristóteles fue uno de los primeros en intentar codificar la «manera correcta de pensar», es decir, un proceso de razonamiento irrefutable. Sus silogismos son esquemas de estructuras de argumentación mediante las que siempre se llega a conclusiones correctas si se parte de premisas correctas

    Ejemplo: Algoritmos de resolución de problemas en matemáticas o ajedrez.


4️⃣ _Actuar de forma racional: el enfoque del agente racional_
    Sistemas que actúan racionalmente – No intentan imitar a los humanos, sino hacer lo correcto en cada situación según el conocimiento disponible. 
    Un _agente racional_ es aquel que actúa con la intención de alcanzar el mejor resultado o, cuando hay incertidumbre, el mejor resultado esperado.

    Ejemplo: Un sistema de recomendación que optimiza sus sugerencias para cada usuario.

    Existen también formas de actuar racionalmente que no implican realizar inferencias. Por ejemplo, el retirar la mano de una estufa caliente es un acto reflejo mucho más eficiente que una respuesta lenta llevada a cabo tras una deliberación cuidadosa.

Cada enfoque tiene su propio método de estudio. Los enfoques basados en los humanos utilizan experimentos y observaciones, mientras que los basados en la racionalidad dependen más de matemáticas e ingeniería. Aunque a veces parecen competir entre sí, en realidad se complementan y han permitido el avance de la IA como la conocemos hoy.


## Historia de la IA

### Génesis de la IA (1943-1955)
1943 - Creación del Primer Modelo de Neuronas Artificiales
Warren McCulloch y Walter Pitts desarrollan un modelo basado en neuronas artificiales, demostrando que cualquier función computacional puede ser implementada mediante redes neuronales.

1949 - Regla de Aprendizaje Hebbiano
Donald Hebb introduce la regla de aprendizaje Hebbiano, que explica cómo se fortalecen las conexiones entre neuronas en función de su activación conjunta.

1950 - Prueba de Turing y Aprendizaje Automático
Alan Turing publica Computing Machinery and Intelligence, donde propone la famosa prueba de Turing y plantea conceptos fundamentales de IA, como el aprendizaje automático.

1951 - Primer Computador Basado en Redes Neuronales (SNARC)
Marvin Minsky y Dean Edmonds construyen el SNARC, la primera computadora basada en redes neuronales, con 3,000 válvulas de vacío.

### Primeros Avances y Expectativas (1952-1969)
1952 - Primeros Programas de Aprendizaje (Juego de Damas)
Arthur Samuel desarrolla un programa de damas capaz de aprender y mejorar su rendimiento con la experiencia.

1956 - Nacimiento Oficial de la Inteligencia Artificial
John McCarthy organiza el taller de Dartmouth junto con Minsky, Shannon y Rochester, donde se acuña el término "Inteligencia Artificial". Allen Newell y Herbert Simon presentan el Teórico Lógico (TL), un programa capaz de demostrar teoremas matemáticos.

1958 - Creación de Lisp y el Generador de Consejos
John McCarthy desarrolla Lisp, el primer lenguaje de programación orientado a IA. También propone el Generador de Consejos, un sistema que razonaba con conocimiento general.

1960 - Mejora en Métodos de Aprendizaje Neuronal
Bernie Widrow y Hoff refinan los métodos de aprendizaje de Hebb y desarrollan los adalines, modelos neuronales mejorados.

1962 - Teorema del Perceptrón
Frank Rosenblatt demuestra que los perceptrones pueden ajustar automáticamente sus conexiones para adaptarse a patrones de entrada.

1963 - Fundación del Laboratorio de IA de Stanford
John McCarthy establece el Laboratorio de Inteligencia Artificial en Stanford, enfocándose en el razonamiento lógico para la resolución de problemas.

1967 - Desarrollo del Programa STUDENT
Daniel Bobrow crea STUDENT, un programa capaz de resolver problemas algebraicos en lenguaje natural.

1968 - Desarrollo del Programa ANALOGY
Tom Evans diseña ANALOGY, un programa que resuelve problemas de analogía geométrica similares a los usados en pruebas de coeficiente intelectual.

1969 - Proyecto Shakey (Primer Robot con IA Integrada)
El Instituto de Investigación de Stanford desarrolla Shakey, el primer robot en integrar razonamiento lógico con acción física.

### Una dosis de realidad (1966-1973)
1966
Se publica un informe que concluye que la traducción automática no ha logrado resultados satisfactorios ni se espera que lo haga en el futuro inmediato. Como consecuencia, el gobierno de EE.UU. retira el financiamiento para la investigación en este campo.

### Sistemas basados en el conocimiento: ¿clave del poder? (1969-1979)

1969
Se publica el libro Perceptrons de Marvin Minsky y Seymour Papert, que demuestra las limitaciones de los perceptrones simples, lo que lleva a la reducción del financiamiento en redes neuronales.

Se desarrolla el programa DENDRAL, uno de los primeros sistemas expertos exitosos, diseñado para inferir estructuras moleculares a partir de datos espectroscópicos.

1971
DENDRAL introduce la separación entre el conocimiento experto (representado en reglas) y el motor de razonamiento, lo que sienta las bases para futuros sistemas expertos.

1973
Se publica el Informe Lighthill, que critica la falta de avances en IA y destaca el problema de la "explosión combinatoria". Como resultado, el gobierno británico retira el apoyo financiero a la investigación en IA, excepto en dos universidades.

Finales de los 70
Se desarrolla el programa MYCIN, un sistema experto en diagnóstico médico que supera a médicos recién graduados en la detección de infecciones sanguíneas.

Se intensifica la investigación sobre comprensión del lenguaje natural, con sistemas como SHRDLU, aunque se evidencia la necesidad de integrar conocimiento del mundo real para mejorar su desempeño.

### La IA se convierte en una industria (desde 1980 hasta el presente)

1980-1988
Nace la industria de la IA con la creación de sistemas expertos comerciales. R1, un sistema de Digital Equipment Corporation, ahorra millones de dólares anuales.

Japón lanza el proyecto de la Quinta Generación para construir computadoras inteligentes, y EE.UU. responde con la creación de la MCC para mantener la competitividad.

La inversión en IA crece hasta alcanzar miles de millones de dólares, pero el entusiasmo se desvanece con la llegada del "Invierno de la IA" debido al fracaso de muchas promesas tecnológicas.


### Regreso de las redes neuronales (desde 1986 hasta el presente)
1986 - Presente
Resurge el interés en redes neuronales con avances en algoritmos de aprendizaje de retroalimentación.Se difunde la obra Parallel Distributed Processing de Rumelhart y McClelland, lo que genera un renovado entusiasmo por los modelos conexionistas. Se abre el debate sobre la complementariedad entre modelos conexionistas y simbólicos en inteligencia artificial.

1982: Judea Pearl y otros investigadores introducen la noción de sistemas expertos normativos basados en la teoría de la decisión.

1985: Peter Cheeseman publica In Defense of Probability, impulsando el uso de la probabilidad en IA.

1986: Eric Horvitz y David Heckerman contribuyen al desarrollo de sistemas expertos normativos.

### IA se convierte en una ciencia (desde 1987 hasta el presente)

1987: Se desarrolla la arquitectura de agente SOAR por Allen Newell, John Laird y Paul Rosenbloom.

1988: Judea Pearl publica Probabilistic Reasoning in Intelligent Systems, promoviendo el uso de redes de Bayes en la IA.

1990: Newell publica trabajos sobre arquitecturas de agentes completos.

### Emergencia de los sistemas inteligentes (desde 1995 hasta el presente)

1995: Se consolida la IA como disciplina científica con metodologías más rigurosas y experimentos estadísticos. Russell y Norvig publican la primera edición de su libro de IA.

1998: David McAllester señala que la IA abandona su aislamiento y se integra con la teoría de la información, modelos estocásticos y métodos formales. Poole, Nilsson y otros adoptan la perspectiva de agentes en sus libros de texto.

### Años 2000 en adelante:

- Se generaliza el uso de modelos de Markov ocultos (MMO) en el reconocimiento del habla.

- La minería de datos se convierte en una industria clave gracias a los avances en redes neuronales y aprendizaje automático.

- La IA se expande hacia Internet con sistemas inteligentes como bots, motores de búsqueda y sistemas de recomendación.

- Se consolida la visión de la IA como el diseño de agentes racionales, unificando subcampos como visión por computadora, robótica y teoría de control.