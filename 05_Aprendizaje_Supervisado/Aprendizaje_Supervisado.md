## Aprendizaje Supervisado

El aprendizaje supervisado consiste en encontrar una funci√≥n ‚Ñé (hip√≥tesis) que aproxime la funci√≥n real ùëì(ùë•) a partir de un conjunto de entrenamiento con pares de entrada-salida. Esta hip√≥tesis se elige dentro de un espacio de hip√≥tesis ùêª, que puede incluir funciones lineales, polinomiales, l√≥gicas, entre otras.

__Selecci√≥n del Espacio de Hip√≥tesis__

- Se puede basar en conocimiento previo o en un an√°lisis exploratorio de datos (gr√°ficos, pruebas estad√≠sticas).
- Se pueden probar diferentes espacios y evaluar cu√°l se ajusta mejor.

__Evaluaci√≥n del Modelo__

- Consistencia: Idealmente, ‚Ñé(ùë•) debe coincidir con ùë¶ para todos los datos de entrenamiento, pero en la pr√°ctica se busca la mejor aproximaci√≥n.

- Generalizaci√≥n: El modelo debe predecir correctamente datos nuevos, lo que se eval√∫a con un conjunto de prueba.

__Ejemplos de Modelos__
Distintas elecciones de ùêª generan diferentes ajustes a los datos:

1. Funciones lineales: Simples, pero pueden no representar bien los datos.

2. Funciones sinusoidales: Se ajustan mejor si los datos tienen periodicidad.

3. Funciones por segmentos lineales: Siguen exactamente los datos, pero pueden sobreajustar.

4. Polinomios de grado alto: Pueden ajustarse perfectamente a los datos de entrenamiento, pero tienen alto riesgo de sobreajuste.

__Sesgo, Varianza y Sobreajuste__

- Sesgo: Restricci√≥n del espacio de hip√≥tesis que impide capturar la complejidad real de los datos (subajuste).
- Varianza: Sensibilidad del modelo a peque√±os cambios en los datos de entrenamiento (sobreajuste).
- Compensaci√≥n sesgo-varianza: Modelos m√°s simples pueden generalizar mejor, mientras que modelos muy complejos pueden ajustarse demasiado a los datos de entrenamiento y fallar en datos nuevos.

__Principio de Simplicidad y Aprendizaje Profundo__

- Navaja de Ockham: Se prefiere la hip√≥tesis m√°s simple que explique los datos.
- Aprendizaje profundo: Aunque las redes neuronales tienen muchos par√°metros, pueden generalizar bien con suficiente datos y computaci√≥n eficiente.

__Expresividad vs. Complejidad__
Modelos m√°s expresivos pueden representar mejor los datos, pero encontrar una buena hip√≥tesis en ellos puede ser computacionalmente dif√≠cil. Se buscan representaciones balanceadas entre expresividad y eficiencia de c√≥mputo.


### Descargar archivos de trabajo
- Casos Practico - [Descargar](https://drive.google.com/file/d/1WQy0Ggc0EUJSDx7n6RhJz78fgjSwOZwr/view?usp=sharing)
- Datos - [Descargar](https://drive.google.com/file/d/1NhlzPS0VeVj4x1oSFYHK3t-5IArzF2Vh/view?usp=sharing)

