# Introducci√≥n al Aprendizaje Automatizado

¬øPor qu√© queremos que una m√°quina aprenda? ¬øPor qu√© no programarla directamente con la soluci√≥n? Hay dos razones principales:

Los desarrolladores no pueden anticipar todas las situaciones futuras. Por ejemplo, un robot que navega laberintos debe aprender el dise√±o de cada nuevo laberinto, y un programa que predice el mercado burs√°til debe adaptarse a cambios econ√≥micos.

A veces los desarrolladores no saben c√≥mo programar la soluci√≥n. Por ejemplo, las personas reconocen caras de familiares de manera subconsciente, pero es dif√≠cil programar esa habilidad sin usar algoritmos de aprendizaje autom√°tico.

## Formas de Aprendizaje

Cualquier componente de un agente inteligente puede mejorarse mediante aprendizaje autom√°tico. La mejora depende de qu√© componente se optimiza, qu√© conocimiento previo posee el agente y qu√© datos y retroalimentaci√≥n tiene disponibles.

Componentes que pueden aprenderse:

1. Reglas de acci√≥n basadas en condiciones.
2. Reconocimiento de patrones a partir de percepciones.
3. Comprensi√≥n de la evoluci√≥n del mundo y efectos de las acciones.
4. Informaci√≥n sobre la utilidad de distintos estados.
5. Valoraci√≥n de la conveniencia de diferentes acciones.
6. Definici√≥n de objetivos.
7. Sistemas de mejora como generadores de problemas y cr√≠ticos.

Por ejemplo, un autom√≥vil aut√≥nomo puede aprender cu√°ndo frenar observando a un conductor humano o identificando autobuses en im√°genes (clasificaci√≥n). Tambi√©n puede aprender los efectos de frenar en diferentes condiciones y ajustar su conducci√≥n para mayor confort del pasajero.

__Aplicaciones del Aprendizaje Autom√°tico (Machine Learning)__

El aprendizaje autom√°tico es una parte esencial del desarrollo de software. Ejemplos incluyen:
- Aceleraci√≥n del an√°lisis de im√°genes astron√≥micas en un factor de 10 millones.
- Reducci√≥n del consumo energ√©tico en centros de datos en un 40%.
- Mejora de arquitecturas de computaci√≥n seg√∫n Google AI.

__Formas de Aprendizaje__

https://www.youtube.com/watch?v=oT3arRRB2Cw

- __Aprendizaje supervisado__: El agente aprende a partir de ejemplos etiquetados (ej. reconocer peatones en im√°genes).
- __Aprendizaje no supervisado__: Encuentra patrones sin etiquetas expl√≠citas (ej. agrupar im√°genes similares).
- __Aprendizaje por refuerzo__: Aprende de recompensas y castigos (ej. mejorar su estrategia en ajedrez).

__Inducci√≥n vs. Deducci√≥n__
La inducci√≥n generaliza a partir de datos (ej. "el sol siempre ha salido, lo har√° ma√±ana"), pero no garantiza certeza, a diferencia de la deducci√≥n l√≥gica.

https://www.youtube.com/watch?v=yKCmn7utNRc&t=426s

__Modelos de Aprendizaje__
El aprendizaje puede manejar datos representados como vectores de atributos (factored), estructuras at√≥micas o modelos relacionales. Seg√∫n la naturaleza de la salida, el problema puede clasificarse como:

- Clasificaci√≥n: Predicci√≥n de valores discretos (ej. soleado/lluvioso).
- Regresi√≥n: Predicci√≥n de valores num√©ricos (ej. temperatura del d√≠a siguiente).

Este cap√≠tulo sienta las bases para entender c√≥mo los agentes pueden aprender y mejorar su rendimiento a partir de la experiencia.

## Aprendizaje Supervisado

El aprendizaje supervisado consiste en encontrar una funci√≥n ‚Ñé (hip√≥tesis) que aproxime la funci√≥n real ùëì(ùë•) a partir de un conjunto de entrenamiento con pares de entrada-salida. Esta hip√≥tesis se elige dentro de un espacio de hip√≥tesis ùêª, que puede incluir funciones lineales, polinomiales, l√≥gicas, entre otras.

__Selecci√≥n del Espacio de Hip√≥tesis__

- Se puede basar en conocimiento previo o en un an√°lisis exploratorio de datos (gr√°ficos, pruebas estad√≠sticas).
- Se pueden probar diferentes espacios y evaluar cu√°l se ajusta mejor.

__Evaluaci√≥n del Modelo__

- Consistencia: Idealmente, ‚Ñé(ùë•) debe coincidir con ùë¶ para todos los datos de entrenamiento, pero en la pr√°ctica se busca la mejor aproximaci√≥n.

- Generalizaci√≥n: El modelo debe predecir correctamente datos nuevos, lo que se eval√∫a con un conjunto de prueba.

__Ejemplos de Modelos__
Distintas elecciones de ùêª generan diferentes ajustes a los datos:

1. Funciones lineales: Simples, pero pueden no representar bien los datos.

2. Funciones sinusoidales: Se ajustan mejor si los datos tienen periodicidad.

3. Funciones por segmentos lineales: Siguen exactamente los datos, pero pueden sobreajustar.

4. Polinomios de grado alto: Pueden ajustarse perfectamente a los datos de entrenamiento, pero tienen alto riesgo de sobreajuste.

__Sesgo, Varianza y Sobreajuste__

- Sesgo: Restricci√≥n del espacio de hip√≥tesis que impide capturar la complejidad real de los datos (subajuste).
- Varianza: Sensibilidad del modelo a peque√±os cambios en los datos de entrenamiento (sobreajuste).
- Compensaci√≥n sesgo-varianza: Modelos m√°s simples pueden generalizar mejor, mientras que modelos muy complejos pueden ajustarse demasiado a los datos de entrenamiento y fallar en datos nuevos.

__Principio de Simplicidad y Aprendizaje Profundo__

- Navaja de Ockham: Se prefiere la hip√≥tesis m√°s simple que explique los datos.
- Aprendizaje profundo: Aunque las redes neuronales tienen muchos par√°metros, pueden generalizar bien con suficiente datos y computaci√≥n eficiente.

__Expresividad vs. Complejidad__
Modelos m√°s expresivos pueden representar mejor los datos, pero encontrar una buena hip√≥tesis en ellos puede ser computacionalmente dif√≠cil. Se buscan representaciones balanceadas entre expresividad y eficiencia de c√≥mputo.










