{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1FeU5dUwyPAto4Sc9jBli5Pu1duIQX7hp\">Abre este Jupyter en Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se muestran algunos de los mecanismos más utilizados para la visualización del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción\n",
    "NSL-KDD es un conjunto de datos sugerido para resolver algunos de los problemas inherentes del conjunto de datos KDD'99 mencionados. Si bien esta nueva versión del conjunto de datos KDD aún presenta algunos de los problemas mencionados por McHugh y podría no ser una representación perfecta de las redes reales existentes, debido a la falta de conjuntos de datos públicos para sistemas de detección de intrusiones (IDS) basados ​​en red, creemos que aún puede aplicarse como un conjunto de datos de referencia eficaz para ayudar a los investigadores a comparar diferentes métodos de detección de intrusiones. Además, el número de registros en los conjuntos de entrenamiento y prueba de NSL-KDD es razonable. Esta ventaja permite ejecutar los experimentos en el conjunto completo sin necesidad de seleccionar aleatoriamente una pequeña porción. En consecuencia, los resultados de la evaluación de diferentes investigaciones serán consistentes y comparables.\n",
    "\n",
    "### Ficheros de datos\n",
    "* <span style=\"color:green\">**KDDTrain+.ARFF**: The full NSL-KDD train set with binary labels in ARFF format</span>\n",
    "* <span style=\"color:green\">**KDDTrain+.TXT**: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format</span>\n",
    "\n",
    "### Descarga de los ficheros de datos\n",
    "https://drive.google.com/file/d/14CQK9EJDCXjATWa97tEdKysZ4v5KsFh_/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lectura del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del conjunto de datos mediante funciones de Python\n",
    "with open(\"datasets/NSL-KDD/KDDTrain+.txt\") as train_set:\n",
    "    df = train_set.readlines()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del conjunto de datos utilizando Pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/NSL-KDD/KDDTrain+.txt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los ficheros en el directorio del conjunto de datos\n",
    "import os\n",
    "\n",
    "os.listdir(\"datasets/NSL-KDD/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un archivo **ARFF (Formato de Archivo de Relación de Atributos)** es un archivo de texto ASCII que describe una lista de instancias que comparten un conjunto de atributos. Los archivos ARFF fueron desarrollados por el Proyecto de Aprendizaje Automático del Departamento de Ciencias de la Computación de la Universidad de Waikato para su uso con el software de aprendizaje automático Weka. Más información: https://www.cs.waikato.ac.nz/ml/weka/arff.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos un nuevo paquete externo para poder leer ficheros arff\n",
    "!pip install liac-arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del conjunto de datos que se encuentra en formato .arff\n",
    "import arff\n",
    "\n",
    "with open('datasets/NSL-KDD/KDDTrain+.arff', 'r') as train_set:\n",
    "    df = arff.load(train_set)\n",
    "\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"attributes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parseamos los atributos para obtener únicamente los nombres\n",
    "atributos = [attr[0] for attr in df[\"attributes\"]]\n",
    "atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el conjunto de datos con Pandas para facilitar la manipulación\n",
    "df = pd.DataFrame(df[\"data\"], columns=atributos)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llegados a este punto lo ideal es construir una función que permita leer el conjunto de datos de manera más limpia. Este tipo de prácticas son de gran utilidad para que nuestro código en el Jupyter Notebook sea más modular y pueda reutilizarse de manera más sencilla para futuros ejercicios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path):\n",
    "    \"\"\"Lectura del conjunto de datos NSL-KDD.\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "    attributes = [attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kdd_dataset('datasets/NSL-KDD/KDDTrain+.arff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Funciones básicas de visualización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El proceso de visualización siempre debe realizarse sobre el trainning set y apartando el test set. Esto evita que nuestro cerebro genere intuiciones del test set que podemos incorporar en nuestro modelo\n",
    "* Una buena práctica es crear una copia del trainning set y jugar con ella. De esta manera, si realizamos transformaciones que dañan el tranning set, el original no se ve afectado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura y copia del conjunto de datos\n",
    "df_orig = load_kdd_dataset('datasets/NSL-KDD/KDDTrain+.arff')\n",
    "df = df_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar en pantalla un número determinado de filas\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información básica sobre el conjunto de datos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información estadística sobre el conjunto de datos\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los valores únicos que tiene un atributo determinado\n",
    "df[\"protocol_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los valores de la característica como un histograma\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "df[\"protocol_type\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representar gráficamente la distribución de los atributos\n",
    "df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funciones avanzadas de visualización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando correlaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se puede calcular el coeficiente de correlación estándar para ver la correlación entre cada par de atributos\n",
    "* El coeficiente de correlación, solo mide **correlaciones lineales**, esto quiere decir que si x va hacia arriba, mediría si y va hacia arriba o hacia abajo.\n",
    "* **Hay que intentar buscar correlaciones sobre todo con el atributo objetivo (el que queremeos predecir), en este caso _class_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El atributo class de nuestro conjunto de datos tiene valores categoricos\n",
    "df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Transformamos los valores del atributo class de categoricos a numéricos\n",
    "labelencoder = LabelEncoder()\n",
    "df[\"class\"] = labelencoder.fit_transform(df[\"class\"])\n",
    "\n",
    "# Transformamos los valores de los atributos categóricos a numéricos\n",
    "df[\"protocol_type\"] = labelencoder.fit_transform(df[\"protocol_type\"])\n",
    "df[\"service\"] = labelencoder.fit_transform(df[\"service\"])\n",
    "df[\"flag\"] = labelencoder.fit_transform(df[\"flag\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la correlación entre los atributos del conjunto de datos\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix[\"class\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar correlación lineal entre todos los atributos del conjunto de datos\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representar gráficamente la matriz de correlación\n",
    "corr = df.corr()\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(corr)\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "plt.yticks(range(len(corr.columns)), corr.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representar gráficamente las correlaciones\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"same_srv_rate\", \"dst_host_srv_count\", \"class\", \"dst_host_same_srv_rate\"]\n",
    "\n",
    "scatter_matrix(df[attributes], figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
