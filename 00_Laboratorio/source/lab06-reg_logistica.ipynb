{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1eQOkYB4XMQdSeHV_pKvt9kSUW8vQo6LQ\">Abre este Jupyter en Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi√≥n Log√≠stica: Detecci√≥n de SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se muestran los fundamentos de la Regresi√≥n Log√≠stica planteando uno de los primeros problemas que fueron solucionados mediante el uso de t√©cnicas de Machine Learning: la detecci√≥n de SPAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import email\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ‚úÖ Descargar stopwords de NLTK\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# üìå Clase de preprocesamiento\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.stemmer = nltk.PorterStemmer()\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "        self.punctuation = list(string.punctuation)\n",
    "\n",
    "    def parse(self, email_path):\n",
    "        with open(email_path, errors='ignore') as e:\n",
    "            msg = email.message_from_file(e)\n",
    "        return None if not msg else self.get_email_content(msg)\n",
    "\n",
    "    def get_email_content(self, msg):\n",
    "        subject = self.tokenize(msg['Subject']) if msg['Subject'] else []\n",
    "        body = self.get_email_body(msg.get_payload(), msg.get_content_type())\n",
    "        return {\n",
    "            \"subject\": subject,\n",
    "            \"body\": body,\n",
    "            \"content_type\": msg.get_content_type()\n",
    "        }\n",
    "\n",
    "    def get_email_body(self, payload, content_type):\n",
    "        body = []\n",
    "        if isinstance(payload, str):\n",
    "            if content_type == 'text/plain':\n",
    "                return self.tokenize(payload)\n",
    "            elif content_type == 'text/html':\n",
    "                return self.tokenize(self.strip_tags(payload))\n",
    "        elif isinstance(payload, list):\n",
    "            for p in payload:\n",
    "                body += self.get_email_body(p.get_payload(), p.get_content_type())\n",
    "        return body\n",
    "\n",
    "    def strip_tags(self, html):\n",
    "        from html.parser import HTMLParser\n",
    "        class MLStripper(HTMLParser):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.fed = []\n",
    "            def handle_data(self, d):\n",
    "                self.fed.append(d)\n",
    "            def get_data(self):\n",
    "                return ''.join(self.fed)\n",
    "        s = MLStripper()\n",
    "        s.feed(html)\n",
    "        return s.get_data()\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        for c in self.punctuation:\n",
    "            text = text.replace(c, \"\")\n",
    "        text = text.replace(\"\\t\", \" \").replace(\"\\n\", \" \")\n",
    "        tokens = list(filter(None, text.split(\" \")))\n",
    "        return [self.stemmer.stem(w.lower()) for w in tokens if w.lower() not in self.stopwords]\n",
    "\n",
    "# ‚úÖ Funciones auxiliares\n",
    "DATASET_PATH = os.path.join(\"datasets\", \"trec07p\")\n",
    "\n",
    "def parse_index(path_to_index, n_elements):\n",
    "    ret_indexes = []\n",
    "    with open(path_to_index) as f:\n",
    "        index = f.readlines()\n",
    "    for i in range(n_elements):\n",
    "        label, rel_path = index[i].split(\" ../\")\n",
    "        path_mail = rel_path.strip().split(\"/\")[-1]\n",
    "        ret_indexes.append({\n",
    "            \"label\": label,\n",
    "            \"email_path\": os.path.join(DATASET_PATH, \"data\", path_mail)\n",
    "        })\n",
    "    return ret_indexes\n",
    "\n",
    "def parse_email(index):\n",
    "    p = Parser()\n",
    "    mail = p.parse(index[\"email_path\"])\n",
    "    return mail, index[\"label\"]\n",
    "\n",
    "def create_prep_dataset(index_path, n_elements):\n",
    "    X, y = [], []\n",
    "    indexes = parse_index(index_path, n_elements)\n",
    "    for i in range(n_elements):\n",
    "        try:\n",
    "            mail, label = parse_email(indexes[i])\n",
    "            X.append(\" \".join(mail['subject']) + \" \" + \" \".join(mail['body']))\n",
    "            y.append(label)\n",
    "        except:\n",
    "            pass\n",
    "    return X, y\n",
    "\n",
    "# ‚úÖ Carga y preprocesamiento de los correos\n",
    "X_train_text, y_train = create_prep_dataset(\"datasets/trec07p/full/index\", 100)\n",
    "\n",
    "# ‚úÖ Vectorizador con solo la palabra 'free'\n",
    "vectorizer = CountVectorizer(vocabulary=['free'])  # Solo esa palabra\n",
    "X_train_single = vectorizer.fit_transform(X_train_text)\n",
    "\n",
    "# ‚úÖ Entrenamiento del modelo de regresi√≥n log√≠stica\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_single, y_train)\n",
    "\n",
    "# ‚úÖ Visualizaci√≥n: funci√≥n log√≠stica\n",
    "theta_0 = clf.intercept_[0]\n",
    "theta_1 = clf.coef_[0][0]\n",
    "\n",
    "# Rango de valores (frecuencia de 'free' de 0 a 10)\n",
    "x_vals = np.linspace(0, 10, 100)\n",
    "logits = theta_0 + theta_1 * x_vals\n",
    "sigmoid = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "# ‚úÖ Gr√°fico de la funci√≥n sigmoide\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_vals, sigmoid, label='P(spam|x)', color='blue')\n",
    "plt.axhline(0.5, color='gray', linestyle='--', label='Umbral de decisi√≥n')\n",
    "plt.title(\"Funci√≥n log√≠stica para la palabra 'free'\")\n",
    "plt.xlabel(\"Cantidad de veces que aparece 'free'\")\n",
    "plt.ylabel(\"Probabilidad de que sea SPAM\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar modelo aprendido\n",
    "print(f\"Modelo: P(spam|x) = 1 / (1 + exp(-({theta_0:.2f} + {theta_1:.2f} * x)))\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
